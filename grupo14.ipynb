{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grupo14.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JALVARADORUIZ/Magister_BigData_UB/blob/main/grupo14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importación de Librerias**"
      ],
      "metadata": {
        "id": "NCSwS3fGoPBZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plKs5MndlXIc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from collections import Counter\n",
        "import string\n",
        "import re\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carga de Data**"
      ],
      "metadata": {
        "id": "Wc0BceuQnvjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_file = \"https://raw.githubusercontent.com/albertojulian/master-ub/main/reviews.txt\"\n",
        "labels_file = \"https://raw.githubusercontent.com/albertojulian/master-ub/main/labels.txt\""
      ],
      "metadata": {
        "id": "owP0HQfgoLCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_reviews = pd.read_csv(reviews_file,header=None, names=['review'])\n",
        "df_labels = pd.read_csv(labels_file, header=None, names=['sentiment'])\n",
        "\n",
        "df = pd.concat([df_reviews,df_labels],axis=1)"
      ],
      "metadata": {
        "id": "zORw3wWzlkPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "_FU7mVZrl0oD",
        "outputId": "db60b67e-80c1-4328-8d78-fc591cd21451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  bromwell high is a cartoon comedy . it ran at ...  positive\n",
              "1  story of a man who has unnatural feelings for ...  negative\n",
              "2  homelessness  or houselessness as george carli...  positive\n",
              "3  airport    starts as a brand new luxury    pla...  negative\n",
              "4  brilliant over  acting by lesley ann warren . ...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19587547-64b5-4a8a-812f-0ba8320b305c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bromwell high is a cartoon comedy . it ran at ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>story of a man who has unnatural feelings for ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>homelessness  or houselessness as george carli...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>airport    starts as a brand new luxury    pla...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brilliant over  acting by lesley ann warren . ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19587547-64b5-4a8a-812f-0ba8320b305c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19587547-64b5-4a8a-812f-0ba8320b305c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19587547-64b5-4a8a-812f-0ba8320b305c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGswqkqZoaZO",
        "outputId": "e25d8043-901a-478d-fc0a-a7acf42fe503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    12500\n",
              "negative    12500\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocesamiento**"
      ],
      "metadata": {
        "id": "WxlZ42Nxn07t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onLerETX-9Wz",
        "outputId": "9fbbb9de-d9c2-41f6-beba-f89052f07b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Eliminar signos que no sean alfanuméricos."
      ],
      "metadata": {
        "id": "IDNOhbyxn-NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_string(s):\n",
        "    # Eliminar todos los caracteres que no sean palabras (todo excepto números y letras)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Reemplazar todas las series de espacios en blanco sin espacio\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # reemplazar dígitos sin espacio\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s"
      ],
      "metadata": {
        "id": "5IGgEM_P8PkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tokenizar cada revisión (convertirla en una lista de palabras).\n",
        "- Generar la lista de palabras distintas de todo el dataset y ordenar por número de veces que se presenta en el dataset, de forma que se puedan seleccionar las “n” más frecuentes.\n",
        "- Asociar cada palabra de la lista con un número identificador."
      ],
      "metadata": {
        "id": "ffCXu1MVujsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tockenize(x,y):\n",
        "    word_list = []\n",
        "    #utilizamos stopwords\n",
        "    stop_words = set(stopwords.words('english')) \n",
        "    for sent in x:\n",
        "        \n",
        "        for word in sent.split():\n",
        "            word = preprocess_string(word)\n",
        "            if word not in stop_words and word != '':\n",
        "                word_list.append(word)\n",
        "  \n",
        "    corpus = Counter(word_list)\n",
        "    # clasificación en base a las palabras más comunes\n",
        "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
        "\n",
        "    # creamos un diccionario\n",
        "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
        "    \n",
        "    # tokenizamos y Generar la lista de palabras distintas de todo el dataset \n",
        "    final_list = []\n",
        "    for sent in x:\n",
        "            final_list.append([onehot_dict[preprocess_string(word)] for word in sent.split() \n",
        "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
        "            \n",
        "    encoded = [1 if label =='positive' else 0 for label in y]  \n",
        "\n",
        "    return np.array(final_list), np.array(encoded),onehot_dict"
      ],
      "metadata": {
        "id": "YZH2U-RqpnB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews, sentiments, vocab = tockenize(df.review, df.sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3GzcgsP9voJ",
        "outputId": "23352c34-2a46-46f5-9c9d-03688be6ee7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tamaño de vocabulario:\", len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RyFK0v6_Vst",
        "outputId": "9d3050ca-8c8d-499e-83cb-618a1ef907c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de vocabulario: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(reviews),len(sentiments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX3SHNPV_aL5",
        "outputId": "60dd0b5d-8dde-4491-877e-895a660796f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Truncar las revisiones a 160 palabras y rellenar con “0” las revisiones que tengan menos palabras."
      ],
      "metadata": {
        "id": "OhCA9J-OqqhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def padding_(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len), dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features"
      ],
      "metadata": {
        "id": "rOFqP7leqkXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = padding_(reviews, 160)\n",
        "y = sentiments"
      ],
      "metadata": {
        "id": "BbHpDk0Erpck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "id": "ZBy2HRAesHoH",
        "outputId": "690ecabb-500a-4059-8284-59fef89440a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dividir los datasets de revisiones y etiquetas en 80% para entrenamiento, 10% para validación y 10% para pruebas."
      ],
      "metadata": {
        "id": "xNN_p1gLtDoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80% de nuestra data para train\n",
        "x_train, y_train = X[:20000], y[:20000]\n",
        "len(x_train),len(y_train)"
      ],
      "metadata": {
        "id": "Ob_30Ao8tCjd",
        "outputId": "956ac21d-6401-4dcd-cf22-5c4c26179a63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 20000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dejamos 10% para validacion\n",
        "x_val, y_val = X[20000:22500], y[20000:22500]\n",
        "len(x_val),len(y_val)"
      ],
      "metadata": {
        "id": "oISJj2t2zE4d",
        "outputId": "8c9f1b91-3da8-4a5e-aecc-21738394bb5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dejamos el 10% para test\n",
        "x_test,y_test = X[22500:25000], y[22500:25000]\n",
        "len(x_test),len(y_test)"
      ],
      "metadata": {
        "id": "hEXhHsjxtn0E",
        "outputId": "8a27f404-57ab-4184-b0fc-4a6b239e7aed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carga del fichero de palabras vectorizadas GloVe de 100 dimensiones (se puede eliminar el resto de ficheros)** "
      ],
      "metadata": {
        "id": "WIsaEKfEzvWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "u1W9sZBvOkby",
        "outputId": "609288fe-bf81-4d28-e3bb-5a810d449a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "#!cp /content/glove.6B.zip /content/drive/MyDrive/data/glove.6B.zip\n",
        "#!unzip /content/drive/MyDrive/data/glove.6B.zip -d /content/drive/MyDrive/data/"
      ],
      "metadata": {
        "id": "frpnGqIdOlMN",
        "outputId": "004d65d8-2eb0-43b4-fcfc-544bc0913892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-30 22:31:59--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-07-30 22:31:59--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-07-30 22:32:00--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.33MB/s    in 2m 50s  \n",
            "\n",
            "2022-07-30 22:34:50 (4.83 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/drive/MyDrive/data/glove.6B.zip\n",
            "  inflating: /content/drive/MyDrive/data/glove.6B.50d.txt  \n",
            "  inflating: /content/drive/MyDrive/data/glove.6B.100d.txt  \n",
            "  inflating: /content/drive/MyDrive/data/glove.6B.200d.txt  \n",
            "  inflating: /content/drive/MyDrive/data/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "f = open('/content/drive/MyDrive/data/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "id": "NhJ7TH2-PNyr",
        "outputId": "9528cbbc-ffc6-4784-b6a6-70356f101e55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  if i < max_words:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "I7OaftNsQF2V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "0e3b8e73-f298-4cad-cfe7-6dd708d251c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3cdf88cf5c06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'max_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Oun0tTT8RNA2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}