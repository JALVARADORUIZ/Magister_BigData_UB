{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M6_AI3_AlvaradoRuizJoseArmando.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "10-B5xihJIljUE9-nQklYJi6mTqQZ0eZI",
      "authorship_tag": "ABX9TyOsMX15rV+gEJ5Vbpb7weX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JALVARADORUIZ/Magister_BigData_UB/blob/main/M6_AI3_AlvaradoRuizJoseArmando.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PADAWAN*: \n",
        "\n",
        "\n",
        "##JOSE ARMANDO ALVARADO RUIZ\n",
        "\n",
        "# **Tema 3. Algoritmo de Random Forest**\n",
        "\n",
        "**Entrega: RECONOCIMIENTO DE NÚMEROS ESCRITOS A MANO**\n",
        "\n",
        "\n",
        "# **Descripción de la tarea**\n",
        "\n",
        "###Contexto\n",
        "\n",
        "La base de datos MNIST (base de datos modificada del Instituto Nacional de Estándares y Tecnología) es una gran base de datos de dígitos escritos a mano que se usa, comúnmente, para entrenar varios sistemas de procesamiento de imágenes. La base de datos MNIST contiene 60.000 imágenes de entrenamiento y 10.000 imágenes de prueba.\n",
        "\n",
        "Se puede descargar manualmente desde la web, sin embargo, la librería TensorFlow la tiene disponible.\n",
        "\n",
        "Disponemos de la siguiente información:\n",
        "\n",
        "* X_train: array de 60.000x28x28, donde cada celda representa un pixel de las diferentes imágenes. Es decir, que tenemos un set de entrenamiento de 60.000 dígitos de 28x28 píxeles (784 pixels) cada uno. Los valores de cada celda representan el código RGB en escala de grises de los diferentes píxeles (0 es blanco y 255 es negro). \n",
        "* Y_train: array de 60.000 filas, donde cada fila tiene el valor entero del dígito de la imagen. \n",
        "* X_test: array de 10.000x28x28, donde cada celda representa un pixel de las diferentes imágenes. Es decir, que tenemos un set de test de 10.000 dígitos de 28x28 píxeles (784 pixels) cada uno. Los valores de cada celda representan el código RGB en escala de grises de los diferentes píxeles (0 es blanco y 255 es negro). \n",
        "* Y_test: array de 10.000 filas, donde cada fila tiene el valor entero del dígito de la imagen.\n",
        "\n",
        "\n",
        "Con estos datos, debes generar un modelo con el algoritmo de Random Forest que pueda encontrar patrones de reconocimiento de imágenes.\n",
        "\n",
        "Se pide seguir lo expuesto en la guía de uso de la librería Scikit-Learn.\n",
        "En dicha página, se lleva a cabo usando el dataset de MNIST de la librería Scikit-Learn y aplicando el algoritmo de Support Vector Machine (SVM).\n",
        "\n",
        "Deberás hacer los cambios que procedan para usar el dataset de TensorFlow (que es más extenso y con más resolución) y cambiar SVM por Random Forest.\n",
        "\n"
      ],
      "metadata": {
        "id": "TI7aGBRDcWJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importación librerias**"
      ],
      "metadata": {
        "id": "qUoKfog-cp6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.options.display.max_columns = None"
      ],
      "metadata": {
        "id": "mwGvdKW2_fdm"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lectura del dataset desde TensorFlow. "
      ],
      "metadata": {
        "id": "kQq9tIAHmfYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "5mWR1bha_NKn"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_train), type(y_train), type(x_test), type(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPGEm_AcL_Rk",
        "outputId": "2635afe4-3f0b-48a3-8f17-506ffbaa0f5b"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXqpu_RBMMmk",
        "outputId": "201c4521-bf44-4933-adc4-bdcc70e3a624"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ver que los datos son del tipo numpy.narray de tres dimensiones, en el caso de los datos de train."
      ],
      "metadata": {
        "id": "YJ5__KpvNAEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicar las conversiones necesarias para pasar de 3d-array a 2d-array (con “reshape”)."
      ],
      "metadata": {
        "id": "7K1734eKM2qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, -1)\n",
        "x_test = x_test.reshape(10000, -1)"
      ],
      "metadata": {
        "id": "QCC8ziNgNOKW"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvU4Y2vGfGXM",
        "outputId": "2a38e4e9-4a4d-4aa2-a80f-9c6f3b8ada5e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta sección se ha transformado las matrices de tres dimensiones a matrices bidimensionales."
      ],
      "metadata": {
        "id": "zs648gn6oIr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crear la variable “n_train” para poder generar diferentes modelos."
      ],
      "metadata": {
        "id": "lsXcsEiszozr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considerando que se cuenta con 60.000 registros en train y 10.000 en test, lo que nos indica que el test representa un 14,2% aproximadamente, se procederá a seleccionar la misma proporción para los n_train solicitados, además se incluirá en el análisis el total de la data de train y en consecuencia la totalidad de test. Así se tendran tres modelos (n_train=600, 6000 y 60000), sin considerar otros parametros en el modelo RandomForestClassifier()."
      ],
      "metadata": {
        "id": "oKV9uB-pt-AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una matriz con 3 elementos con los valores asociados a train y test:\n",
        "\n",
        "n_train = [(600,100),(6000,1000),(60000,10000)]\n"
      ],
      "metadata": {
        "id": "e7gMFkFpxzCi"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generar un modelo con cada uno de los siguientes valores de n_train"
      ],
      "metadata": {
        "id": "rJ2Mpsyqp9j7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for val in n_train:\n",
        "  # Defino los set en entrenamientos y test de diferentes tamaños:\n",
        "  X_train_sub = x_train[0:val[0]]\n",
        "  y_train_sub = y_train[0:val[0]]\n",
        "\n",
        "  X_test_sub = x_test[0:val[1]]\n",
        "  y_test_sub = y_test[0:val[1]]\n",
        "\n",
        "  rf_model = RandomForestClassifier(random_state=0, n_jobs=5)\n",
        "  rf_model.fit(X_train_sub,y_train_sub)\n",
        "  print(f\"Precision para n_train: {str(val[0])} train / {str(val[1])} test \\n\")\n",
        "  pred_train = rf_model.predict(X_train_sub)\n",
        "  pred_test = rf_model.predict(X_test_sub)\n",
        "  print(\"Precisión sobre los datos de entrenamiento: {:.2f}\".format(100.0*rf_model.score(X_train_sub, y_train_sub)))\n",
        "  print(\"Precisión sobre los datos de test: {:.2f}\".format(100.0*rf_model.score(X_test_sub, y_test_sub)))\n",
        "  print(\"\\n\")\n",
        "  print(f\"Classification report for classifier {rf_model}:\\n\"\n",
        "      f\"{metrics.classification_report(y_test_sub, pred_test)}\\n\")\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_siobsi7zgBO",
        "outputId": "08ae0e9d-c77b-4d8c-ba7c-e95dfa77d98c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision para n_train: 600 train / 100 test \n",
            "\n",
            "Precisión sobre los datos de entrenamiento: 100.00\n",
            "Precisión sobre los datos de test: 86.00\n",
            "\n",
            "\n",
            "Classification report for classifier RandomForestClassifier(n_jobs=5, random_state=0):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       0.64      0.88      0.74         8\n",
            "           3       0.92      1.00      0.96        11\n",
            "           4       0.86      0.86      0.86        14\n",
            "           5       1.00      0.57      0.73         7\n",
            "           6       0.86      0.60      0.71        10\n",
            "           7       0.93      0.87      0.90        15\n",
            "           8       0.50      0.50      0.50         2\n",
            "           9       0.77      0.91      0.83        11\n",
            "\n",
            "    accuracy                           0.86       100\n",
            "   macro avg       0.84      0.82      0.82       100\n",
            "weighted avg       0.87      0.86      0.86       100\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Precision para n_train: 6000 train / 1000 test \n",
            "\n",
            "Precisión sobre los datos de entrenamiento: 100.00\n",
            "Precisión sobre los datos de test: 93.00\n",
            "\n",
            "\n",
            "Classification report for classifier RandomForestClassifier(n_jobs=5, random_state=0):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.99      0.96        85\n",
            "           1       0.98      0.98      0.98       126\n",
            "           2       0.94      0.92      0.93       116\n",
            "           3       0.94      0.91      0.92       107\n",
            "           4       0.93      0.91      0.92       110\n",
            "           5       0.93      0.95      0.94        87\n",
            "           6       0.94      0.94      0.94        87\n",
            "           7       0.94      0.91      0.92        99\n",
            "           8       0.86      0.85      0.86        89\n",
            "           9       0.87      0.94      0.90        94\n",
            "\n",
            "    accuracy                           0.93      1000\n",
            "   macro avg       0.93      0.93      0.93      1000\n",
            "weighted avg       0.93      0.93      0.93      1000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Precision para n_train: 60000 train / 10000 test \n",
            "\n",
            "Precisión sobre los datos de entrenamiento: 100.00\n",
            "Precisión sobre los datos de test: 97.05\n",
            "\n",
            "\n",
            "Classification report for classifier RandomForestClassifier(n_jobs=5, random_state=0):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.96      0.97      0.97      1032\n",
            "           3       0.96      0.96      0.96      1010\n",
            "           4       0.98      0.98      0.98       982\n",
            "           5       0.97      0.97      0.97       892\n",
            "           6       0.97      0.98      0.98       958\n",
            "           7       0.97      0.96      0.97      1028\n",
            "           8       0.96      0.95      0.96       974\n",
            "           9       0.96      0.96      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los tres modelos se ha entrenado utilizando los hiperparámetros con su valor por defecto, así se puede concluir que:\n",
        "\n",
        "* En el primer modelo con n_train = 600 nuestro accuracy fue de 100% para el train y de un 86% para test. Esto se explica en la cantidad de registros de entrenamientos, que es menor a la cantidad de predictores que contamos (784). Así el modelo presenta overfitting.\n",
        "\n",
        "* En el modelo con n_train = 6000 nuestro accuracy en train es del 100% y en test del 93%. "
      ],
      "metadata": {
        "id": "Fa6Ec__7vaB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Realizar diferentes modelos cambiando los valores de n_estimators y max_depth. \n"
      ],
      "metadata": {
        "id": "Y-_moZ6jQIiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos RandomizedSearchCV de scikit-learn basado en Cross-Validation."
      ],
      "metadata": {
        "id": "IolwG58Ox6Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeros de arboles en Random Forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 300, num = 10)]\n",
        "\n",
        "# Número de características a considerar en cada división\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# Numero maximo de nivel de los arboles\n",
        "max_depth = [int(x) for x in np.linspace(start = 2, stop = 9, num = 10)]\n"
      ],
      "metadata": {
        "id": "oqMaCmKe7Qei"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth\n",
        "             }"
      ],
      "metadata": {
        "id": "QlvFnl597sSw"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_RandomGrid = RandomizedSearchCV(estimator = RandomForestClassifier(random_state = 0), \n",
        "                                   param_distributions = param_grid, cv = 5, verbose=2, n_jobs = -1, random_state = 0)"
      ],
      "metadata": {
        "id": "kHTB6c3t79Y1"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo n_train = 600"
      ],
      "metadata": {
        "id": "y9jBf3Sfz5cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_600 = x_train[0:600]\n",
        "y_train_600 = y_train[0:600]\n",
        "\n",
        "X_test_100 = x_test[0:100]\n",
        "y_test_100 = y_test[0:100]"
      ],
      "metadata": {
        "id": "5p4i5ETTzTmi"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_RandomGrid.fit(X_train_600, y_train_600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "398lH-pA8QG1",
        "outputId": "9cd7aa08-6134-4f26-b415-942b97fe8bf1"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=0),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'max_depth': [2, 2, 3, 4, 5, 5, 6, 7, 8,\n",
              "                                                      9],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'n_estimators': [10, 42, 74, 106, 138,\n",
              "                                                         171, 203, 235, 267,\n",
              "                                                         300]},\n",
              "                   random_state=0, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_RandomGrid.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXA7pKIb8ue4",
        "outputId": "f3f052d7-6892-4ad2-c2cb-604aec40cf86"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 235}"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train Accuracy : {rf_RandomGrid.score(X_train_600,y_train_600):.2f}')\n",
        "print(f'Test Accuracy  : {rf_RandomGrid.score(X_test_100,y_test_100):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JzuBAe2_RMx",
        "outputId": "253bd63e-8f33-4e16-aa96-73df3a9c433a"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy : 1.00\n",
            "Test Accuracy  : 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo n_train = 6000"
      ],
      "metadata": {
        "id": "OB_940lq9800"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_6000 = x_train[0:6000]\n",
        "y_train_6000 = y_train[0:6000]\n",
        "\n",
        "X_test_1000 = x_test[0:1000]\n",
        "y_test_1000 = y_test[0:1000]"
      ],
      "metadata": {
        "id": "UKmHxkfq98AQ"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_RandomGrid.fit(X_train_6000, y_train_6000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABQWWUAq-GsN",
        "outputId": "dca3a34e-501a-4b8b-db98-d47e44dc91f6"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=0),\n",
              "                   n_jobs=-1,\n",
              "                   param_distributions={'max_depth': [2, 2, 3, 4, 5, 5, 6, 7, 8,\n",
              "                                                      9],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'n_estimators': [10, 42, 74, 106, 138,\n",
              "                                                         171, 203, 235, 267,\n",
              "                                                         300]},\n",
              "                   random_state=0, verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_RandomGrid.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdqUnfWu-IkG",
        "outputId": "383b917b-6192-4747-d458-e966930ee1bc"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 9, 'max_features': 'auto', 'n_estimators': 74}"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train Accuracy : {rf_RandomGrid.score(X_train_6000,y_train_6000):.2f}')\n",
        "print(f'Test Accuracy  : {rf_RandomGrid.score(X_test_1000,y_test_1000):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzoCyylp_WQZ",
        "outputId": "c4edfb40-fa7b-4ad2-f337-a3782a1b14d8"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy : 0.99\n",
            "Test Accuracy  : 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo n_train = 60000"
      ],
      "metadata": {
        "id": "l-34vaoz-KT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_60000 = x_train\n",
        "y_train_60000 = y_train\n",
        "\n",
        "X_test_10000 = x_test\n",
        "y_test_10000 = y_test"
      ],
      "metadata": {
        "id": "fmN-Fj67-OjZ"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_RandomGrid.fit(X_train_60000, y_train_60000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvEKcj47-S5c",
        "outputId": "b279c073-2de9-47a5-b303-abbfabe9a83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_RandomGrid.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye3IdtQr-U9R",
        "outputId": "09f1ba6b-ad2e-4b61-be7b-f5cfc44ea069"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train Accuracy : {rf_RandomGrid.score(X_train_60000,y_train_60000):.2f}')\n",
        "print(f'Test Accuracy  : {rf_RandomGrid.score(X_test_10000,y_test_10000):.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_wzLX4C_cwB",
        "outputId": "d09a66d7-4898-48d2-ec78-4371dfbb647e"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy : 0.92\n",
            "Test Accuracy  : 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comentar los resultados de los diferentes modelos. "
      ],
      "metadata": {
        "id": "BlsuVf0dtMEM"
      }
    }
  ]
}